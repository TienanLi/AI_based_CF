{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from tianshou.policy import DDPGPolicy\n",
    "from tianshou.utils.net.common import Net\n",
    "from tianshou.exploration import GaussianNoise\n",
    "from tianshou.trainer import offpolicy_trainer\n",
    "from tianshou.utils.net.continuous import Actor, Critic\n",
    "from tianshou.data import Collector, ReplayBuffer, VectorReplayBuffer, to_numpy\n",
    "import torch\n",
    "import datetime\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations shape: (3,)\n",
      "Actions shape: (1,)\n",
      "liming\n"
     ]
    }
   ],
   "source": [
    "from CF_env import CFEnv\n",
    "\n",
    "env = CFEnv('liming')\n",
    "train_envs = CFEnv('liming')\n",
    "test_envs = CFEnv('liming')\n",
    "\n",
    "\n",
    "state_shape = env.observation_space.shape \n",
    "action_shape = env.action_space.shape\n",
    "print(\"Observations shape:\", state_shape)\n",
    "print(\"Actions shape:\", action_shape)\n",
    "print(env.rewardName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1: 10001it [02:37, 63.37it/s, env_step=10000, len=1614, loss/actor=-229.923, loss/critic=63.642, n/ep=0, n/st=1, rew=40632.07]\n",
      "Epoch #2:   0%| | 12/10000 [00:00<01:53, 88.20it/s, env_step=10012, len=1614, loss/actor=-230.024, loss/critic=66.261, "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: test_reward: 40891.589844 ± 0.000000, best_reward: 40891.589844 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2: 10001it [02:38, 63.16it/s, env_step=20000, len=1614, loss/actor=-420.376, loss/critic=128.441, n/ep=0, n/st=1, rew=42468.16]\n",
      "Epoch #3:   0%| | 8/10000 [00:00<02:54, 57.30it/s, env_step=20008, len=1614, loss/actor=-420.518, loss/critic=130.752, "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #2: test_reward: 42263.136719 ± 0.000000, best_reward: 42263.136719 ± 0.000000 in #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #3: 10001it [02:36, 64.01it/s, env_step=30000, len=1614, loss/actor=-616.148, loss/critic=202.294, n/ep=0, n/st=1, rew=43379.03]\n",
      "Epoch #4:   0%| | 13/10000 [00:00<01:57, 85.13it/s, env_step=30013, len=1614, loss/actor=-617.315, loss/critic=234.140,"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #3: test_reward: 44054.273438 ± 0.000000, best_reward: 44054.273438 ± 0.000000 in #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #4: 10001it [02:34, 64.93it/s, env_step=40000, len=1614, loss/actor=-804.012, loss/critic=305.962, n/ep=0, n/st=1, rew=44372.80]\n",
      "Epoch #5:   0%| | 11/10000 [00:00<02:06, 78.97it/s, env_step=40011, len=1614, loss/actor=-804.315, loss/critic=359.564,"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #4: test_reward: 46337.648438 ± 0.000000, best_reward: 46337.648438 ± 0.000000 in #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #5: 10001it [02:19, 71.88it/s, env_step=50000, len=1614, loss/actor=-980.072, loss/critic=578.034, n/ep=0, n/st=1, rew=45069.06]\n",
      "Epoch #6:   0%| | 13/10000 [00:00<01:52, 88.57it/s, env_step=50013, len=1614, loss/actor=-980.833, loss/critic=609.943,"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5: test_reward: 45442.128906 ± 0.000000, best_reward: 46337.648438 ± 0.000000 in #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #6: 10001it [02:19, 71.90it/s, env_step=60000, len=1614, loss/actor=-1147.558, loss/critic=666.832, n/ep=0, n/st=1, rew=45783.32]\n",
      "Epoch #7:   0%| | 14/10000 [00:00<01:49, 91.13it/s, env_step=60014, len=1614, loss/actor=-1147.238, loss/critic=740.023"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #6: test_reward: 45923.070312 ± 0.000000, best_reward: 46337.648438 ± 0.000000 in #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #7: 10001it [02:14, 74.21it/s, env_step=70000, len=1614, loss/actor=-1297.860, loss/critic=1243.384, n/ep=0, n/st=1, rew=45617.04]\n",
      "Epoch #8:   0%| | 14/10000 [00:00<01:56, 85.99it/s, env_step=70014, len=1614, loss/actor=-1296.487, loss/critic=1162.58"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #7: test_reward: 45793.753906 ± 0.000000, best_reward: 46337.648438 ± 0.000000 in #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #8: 10001it [02:17, 72.87it/s, env_step=80000, len=1614, loss/actor=-1441.394, loss/critic=1594.239, n/ep=0, n/st=1, rew=45726.77]\n",
      "Epoch #9:   0%| | 13/10000 [00:00<01:56, 86.05it/s, env_step=80013, len=1614, loss/actor=-1442.940, loss/critic=1677.39"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #8: test_reward: 45980.355469 ± 0.000000, best_reward: 46337.648438 ± 0.000000 in #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #9: 10001it [02:18, 72.15it/s, env_step=90000, len=1614, loss/actor=-1586.963, loss/critic=1846.996, n/ep=0, n/st=1, rew=45723.01]\n",
      "Epoch #10:   0%| | 12/10000 [00:00<02:08, 77.85it/s, env_step=90012, len=1614, loss/actor=-1586.783, loss/critic=1845.1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #9: test_reward: 45954.214844 ± 0.000000, best_reward: 46337.648438 ± 0.000000 in #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #10: 10001it [02:18, 72.32it/s, env_step=100000, len=1614, loss/actor=-1745.678, loss/critic=1130.187, n/ep=0, n/st=1, rew=45757.05]\n",
      "Epoch #11:   0%| | 12/10000 [00:00<02:06, 78.99it/s, env_step=100012, len=1614, loss/actor=-1745.609, loss/critic=1258."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #10: test_reward: 46062.062500 ± 0.000000, best_reward: 46337.648438 ± 0.000000 in #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #11: 10001it [02:34, 64.62it/s, env_step=110000, len=1614, loss/actor=-1879.185, loss/critic=2571.417, n/ep=0, n/st=1, rew=45912.95]\n",
      "Epoch #12:   0%| | 12/10000 [00:00<02:16, 73.16it/s, env_step=110012, len=1614, loss/actor=-1879.532, loss/critic=2385."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #11: test_reward: 45363.378906 ± 0.000000, best_reward: 46337.648438 ± 0.000000 in #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #12: 10001it [02:55, 56.97it/s, env_step=120000, len=1614, loss/actor=-1981.571, loss/critic=3877.673, n/ep=0, n/st=1, rew=44728.08]\n",
      "Epoch #13:   0%| | 11/10000 [00:00<02:25, 68.56it/s, env_step=120011, len=1614, loss/actor=-1981.974, loss/critic=3566."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #12: test_reward: 45041.894531 ± 0.000000, best_reward: 46337.648438 ± 0.000000 in #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #13: 10001it [02:34, 64.55it/s, env_step=130000, len=1614, loss/actor=-2058.547, loss/critic=3199.442, n/ep=0, n/st=1, rew=44201.76]\n",
      "Epoch #14:   0%| | 13/10000 [00:00<02:10, 76.39it/s, env_step=130013, len=1614, loss/actor=-2058.826, loss/critic=3029."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #13: test_reward: 44846.179688 ± 0.000000, best_reward: 46337.648438 ± 0.000000 in #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #14: 10001it [03:05, 53.81it/s, env_step=140000, len=846, loss/actor=-2124.714, loss/critic=2874.476, n/ep=0, n/st=1, rew=21008.17]\n",
      "Epoch #15:   0%| | 11/10000 [00:00<02:23, 69.75it/s, env_step=140011, len=846, loss/actor=-2124.550, loss/critic=2514.1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #14: test_reward: 44016.648438 ± 0.000000, best_reward: 46337.648438 ± 0.000000 in #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #15: 10001it [02:37, 63.62it/s, env_step=150000, len=1614, loss/actor=-2186.550, loss/critic=2842.331, n/ep=0, n/st=1, rew=44000.29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #15: test_reward: 44594.160156 ± 0.000000, best_reward: 46337.648438 ± 0.000000 in #4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "resume_path = None\n",
    "\n",
    "seed = 1\n",
    "actor_lr = 1e-4\n",
    "critic_lr = 1e-3\n",
    "tau = .001\n",
    "gamma = .99\n",
    "exploration_noise = .15\n",
    "buffer_size = 100000\n",
    "batch_size = 256\n",
    "\n",
    "# seed\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "train_envs.seed(seed)\n",
    "test_envs.seed(seed)\n",
    "\n",
    "# model\n",
    "net_a = Net(state_shape, hidden_sizes=[256, 256], device='cuda')\n",
    "actor = Actor(net_a, action_shape, device='cuda').to('cuda')\n",
    "actor_optim = torch.optim.Adam(actor.parameters(), lr=actor_lr)\n",
    "\n",
    "net_c = Net(state_shape, action_shape,\n",
    "            hidden_sizes=[256, 256],\n",
    "            concat=True, device='cuda')\n",
    "critic = Critic(net_c, device='cuda').to('cuda')\n",
    "critic_optim = torch.optim.Adam(critic.parameters(), lr=critic_lr)\n",
    "\n",
    "policy = DDPGPolicy(\n",
    "    actor, actor_optim, critic, critic_optim,\n",
    "    tau=tau, gamma=gamma,\n",
    "    exploration_noise=GaussianNoise(sigma=exploration_noise),\n",
    "    estimation_step=1, action_space=action_shape)\n",
    "\n",
    "# load a previous policy\n",
    "if resume_path:\n",
    "    policy.load_state_dict(torch.load(resume_path, map_location='cuda'))\n",
    "    print(\"Loaded agent from: \", resume_path)\n",
    "\n",
    "# collector\n",
    "\n",
    "buffer = ReplayBuffer(buffer_size)\n",
    "train_collector = Collector(policy, train_envs, buffer, exploration_noise=True)\n",
    "test_collector = Collector(policy, test_envs)\n",
    "train_collector.collect(n_step=buffer_size // 4, random=True)\n",
    "\n",
    "# log\n",
    "t0 = datetime.datetime.now().strftime(\"%m%d_%H%M%S\")\n",
    "log_file = f'seed_{seed}_{t0}_ddpg'\n",
    "log_path = os.path.join('log', 'ddpg')\n",
    "\n",
    "def save_fn(policy):\n",
    "    torch.save(policy.state_dict(), os.path.join(log_path, log_file + '_policy.pth'))\n",
    "    \n",
    "# trainer\n",
    "result = offpolicy_trainer(\n",
    "    policy, train_collector, test_collector, max_epoch=15,\n",
    "    step_per_epoch=10000, step_per_collect=1, episode_per_test= 1,\n",
    "    batch_size=batch_size, save_fn=save_fn,\n",
    "    update_per_step=1, test_in_train=False)\n",
    "\n",
    "# Let's watch its performance!\n",
    "# print('\\n start testing')\n",
    "# policy.eval()\n",
    "# test_envs.seed(seed)\n",
    "# test_collector.reset()\n",
    "# result = test_collector.collect(n_episode=1)\n",
    "# print(f'Final reward: {result[\"rews\"].mean()}, length: {result[\"lens\"].mean()}')\n",
    "\n",
    "#save policy\n",
    "# torch.save(policy.state_dict(), os.path.join(log_path, log_file + '_policy.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward(acceleration, newSpacing, follower_speed, leader_speed):\n",
    "    newTimeGap = newSpacing / (follower_speed + .001)\n",
    "    expected_speed = 33.5\n",
    "    expected_time_gap = 1\n",
    "    alpha = 1\n",
    "    beta = 1\n",
    "    gamma = 1\n",
    "    delta = 4\n",
    "    reward = 0\n",
    "    \n",
    "    # time headway\n",
    "    penalty1 = [[0]]\n",
    "    if expected_time_gap > newTimeGap > 0:\n",
    "        penalty1 = - alpha * (100 - 100 * np.sqrt(max(0, expected_time_gap-(expected_time_gap-newTimeGap)**2)))\n",
    "        reward += penalty1\n",
    "\n",
    "    # speed reward\n",
    "    reward2 = beta * min(expected_speed, follower_speed)\n",
    "    reward += reward2\n",
    "\n",
    "    #speed diff reward\n",
    "    reward3 = [[0]]\n",
    "    if newTimeGap < expected_time_gap and leader_speed > follower_speed:\n",
    "        reward3 = gamma * (leader_speed - follower_speed) * (expected_time_gap - newTimeGap)\n",
    "        reward += reward3\n",
    "        \n",
    "    penalty4 = - delta * acceleration ** 2\n",
    "    reward += penalty4\n",
    "\n",
    "    return reward, penalty1, reward2, reward3, penalty4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded agent from:  seed_1_0508_170045_ddpg\n"
     ]
    }
   ],
   "source": [
    "policy.load_state_dict(torch.load(os.getcwd() + '\\\\' + os.path.join(log_path, log_file + '_policy.pth'), \n",
    "                                  map_location='cuda'))\n",
    "print(\"Loaded agent from: \", log_file)\n",
    "policy.eval()\n",
    "rewardHist = [[np.nan] * 4]\n",
    "\n",
    "from CF_env import vehicle\n",
    "SIM_RESOLUTION = .1\n",
    "USED_HISTORY_STAMP  = 1\n",
    "leadSpeedProfile = np.genfromtxt('test_leader.csv', delimiter=',')\n",
    "leaderLoc = [0]\n",
    "followerLoc = [-30]\n",
    "for v in leadSpeedProfile[1:USED_HISTORY_STAMP]:\n",
    "    leaderLoc.append(leaderLoc[-1] + v * SIM_RESOLUTION)\n",
    "    followerLoc.append(followerLoc[-1] + v * SIM_RESOLUTION)\n",
    "follower = vehicle(leadSpeedProfile[:USED_HISTORY_STAMP], followerLoc)\n",
    "leader = vehicle(leadSpeedProfile[:USED_HISTORY_STAMP], leaderLoc)\n",
    "followerSpeedProfile = leadSpeedProfile[:USED_HISTORY_STAMP]\n",
    "followerSpacing = np.array([30] * USED_HISTORY_STAMP)\n",
    "observation = np.concatenate((leader.speedT, follower.speedT,\n",
    "                          [leader.locT[i] - follower.locT[i] for i in range(USED_HISTORY_STAMP)]))\n",
    "\n",
    "t = USED_HISTORY_STAMP\n",
    "while True:\n",
    "    with torch.no_grad():  \n",
    "        obs = np.array([observation])\n",
    "        result = policy.actor(obs)\n",
    "    act = to_numpy(result[0])\n",
    "    action = policy.map_action(act)\n",
    "    \n",
    "    follower.action_a(action)\n",
    "    leader.action_v(leadSpeedProfile[t])\n",
    "    newSpacing = leader.location - follower.location\n",
    "    newStates = np.concatenate((leader.speedT, follower.speedT,\n",
    "                          [leader.locT[i] - follower.locT[i] for i in range(USED_HISTORY_STAMP)]))\n",
    "    followerSpeedProfile = np.append(followerSpeedProfile, [follower.speed])\n",
    "    followerSpacing = np.append(followerSpacing, newSpacing)\n",
    "    reward, penalty1, reward2, reward3, penalty4 = get_reward(action, \n",
    "                                                              newSpacing, \n",
    "                                                              follower.speed, \n",
    "                                                              leader.speed)\n",
    "    rewardHist.append([i[0][0] for i in [penalty1, reward2, reward3, penalty4]])\n",
    "    #current obs\n",
    "    t += 1\n",
    "    observation = newStates\n",
    "    if newSpacing < 0 or t >= len(leadSpeedProfile):\n",
    "        done = 1\n",
    "    else:\n",
    "        done = 0\n",
    "        \n",
    "    if done:\n",
    "        break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (2828,) and (2256,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-8672293ab512>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleadSpeedProfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleadSpeedProfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'leader'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleadSpeedProfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollowerSpeedProfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'follower'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time(s)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'speed(m/s)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2824\u001b[0m     return gca().plot(\n\u001b[0;32m   2825\u001b[0m         \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2826\u001b[1;33m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2827\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1741\u001b[0m         \"\"\"\n\u001b[0;32m   1742\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1743\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1744\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[0;32m    400\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[0;32m    401\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (2828,) and (2256,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize = (10, 3))\n",
    "plt.plot(np.arange(len(leadSpeedProfile)) / 10, leadSpeedProfile, label = 'leader')\n",
    "plt.plot(np.arange(len(leadSpeedProfile)) / 10, followerSpeedProfile, label = 'follower')\n",
    "plt.xlabel('time(s)')\n",
    "plt.ylabel('speed(m/s)')\n",
    "# plt.ylim(22.5, 32.5)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (10, 3))\n",
    "plt.plot(np.arange(len(leadSpeedProfile)) / 10, followerSpacing)\n",
    "plt.xlabel('time(s)')\n",
    "plt.ylabel('spacing(m)')\n",
    "plt.grid(True)\n",
    "# plt.ylim(20, 45)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(min(followerSpeedProfile[:1000]),2), round(min(followerSpeedProfile[1000:]),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(os.path.join(log_path, log_file + 'trajInfo'), 'wb')\n",
    "pickle.dump([leadSpeedProfile, followerSpeedProfile, followerSpacing], file)\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
